{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googlemaps in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.10.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests<3.0,>=2.20.0 in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from googlemaps) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = open('API.txt','r').read()\n",
    "map_client = googlemaps.Client(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the cordinates of the all neighborhoods in the property dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of neighborhood names in Baltimore\n",
    "neighborhood_names = [\n",
    "    \"Mount Washington\",\n",
    "    \"Fells Point\",\n",
    "    \"Clifton\",\n",
    "    \"Downtown\",\n",
    "    \"Arlington\",\n",
    "    \"Carroll\",\n",
    "    \"Purnell\",\n",
    "    \"Greater Northwood Covenant Association\",\n",
    "    \"Northwood\",\n",
    "    \"Locust Point\",\n",
    "    \"Lakeland\",\n",
    "    \"Bolton Hill\",\n",
    "    \"Highlandtown\",\n",
    "    \"Gwynn Oak\",\n",
    "    \"Druid Hill Park\",\n",
    "    \"Otterbein\",\n",
    "    \"Franklintown\",\n",
    "    \"Waverly\",\n",
    "    \"Charles Village\",\n",
    "    \"Old Goucher\",\n",
    "    \"Cherry Hill\",\n",
    "    \"South Baltimore\",\n",
    "    \"Woodberry\",\n",
    "    \"Govans\",\n",
    "    \"Sharp Leadenhall\",\n",
    "    \"Tuscany - Canterbury\",\n",
    "    \"East Case\",\n",
    "    \"Grove Park\",\n",
    "    \"Mid-Town Belvedere\",\n",
    "    \"New North Roland Park - Poplar Hill\",\n",
    "    \"Mosher\",\n",
    "    \"Middle East\",\n",
    "    \"Riverside\",\n",
    "    \"Garwyn Oaks\",\n",
    "    \"Mount Holly\",\n",
    "    \"Elwood Park\",\n",
    "    \"Federal Hill-Montgomery\",\n",
    "    \"West Forest Park\",\n",
    "    \"Inner Harbor\",\n",
    "    \"Ridgely's Delight\",\n",
    "    \"Ednor Gardens - Lakeside\",\n",
    "    \"Brooklyn\",\n",
    "    \"Raspeburg\",\n",
    "    \"Medfield\",\n",
    "    \"Panway - Braddish\",\n",
    "    \"Forest Park\",\n",
    "    \"Harford - Echodale - Perring Parkway\",\n",
    "    \"Station North\",\n",
    "    \"Upper Fells Point\",\n",
    "    \"Hampden\",\n",
    "    \"Pen Lucy\",\n",
    "    \"Oakenshawe\",\n",
    "    \"Harwood\",\n",
    "    \"Coldstream - Homestead - Montebello\",\n",
    "    \"Bridgeview-Greenlawn\",\n",
    "    \"Gay Street\",\n",
    "    \"Franklin\",\n",
    "    \"Pigtown\",\n",
    "    \"Orangeville\",\n",
    "    \"Better Waverly\",\n",
    "    \"Butchers Hill\",\n",
    "    \"Evergreen Lawn\",\n",
    "    \"Morrell Park\",\n",
    "    \"Glenham-Belford\",\n",
    "    \"Western\",\n",
    "    \"Madison - Eastend\",\n",
    "    \"Walbrook\",\n",
    "    \"Abell\",\n",
    "    \"East Baltimore Midway\",\n",
    "    \"Remington\",\n",
    "    \"Coppin Heights\",\n",
    "    \"Hollins Market\",\n",
    "    \"Lauraville\",\n",
    "    \"Mondawmin\",\n",
    "    \"Canton\",\n",
    "    \"Barre Circle\",\n",
    "    \"Barclay\",\n",
    "    \"Windsor Hills\",\n",
    "    \"Wyndhurst\",\n",
    "    \"Wyman Park\",\n",
    "    \"Rosemont\",\n",
    "    \"NW Community Action\",\n",
    "    \"Winchester\",\n",
    "    \"Woodring\",\n",
    "    \"Curtis Bay\",\n",
    "    \"Milton - Montford\",\n",
    "]\n",
    "\n",
    "# Create an empty list to store neighborhood data\n",
    "neighborhood_data = []\n",
    "\n",
    "# Function to geocode neighborhood names and get coordinates and radii\n",
    "def geocode_neighborhoods(names):\n",
    "    for name in names:\n",
    "        try:\n",
    "            # Geocode the neighborhood name\n",
    "            geocode_result = map_client.geocode(name + ', Baltimore, MD, USA')\n",
    "\n",
    "            # Extracting latitude and longitude from the geocoding result\n",
    "            if geocode_result and 'geometry' in geocode_result[0]:\n",
    "                location = geocode_result[0]['geometry']['location']\n",
    "                latitude = location['lat']\n",
    "                longitude = location['lng']\n",
    "\n",
    "                radius = 2000\n",
    "\n",
    "                # Create a dictionary with neighborhood data\n",
    "                neighborhood_info = {\n",
    "                    \"name\": name,\n",
    "                    \"location\": f\"{latitude},{longitude}\",\n",
    "                    \"radius\": radius\n",
    "                }\n",
    "\n",
    "                neighborhood_data.append(neighborhood_info)\n",
    "            else:\n",
    "                print(f\"Could not geocode {name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error geocoding {name}: {str(e)}\")\n",
    "\n",
    "# Calling the function to geocode neighborhood names\n",
    "geocode_neighborhoods(neighborhood_names)\n",
    "\n",
    "# Creating a DataFrame from the neighborhood data\n",
    "neighborhood_df = pd.DataFrame(neighborhood_data)\n",
    "\n",
    "# Print the DataFrame or save it to a CSV file\n",
    "print(neighborhood_df)\n",
    "neighborhood_df.to_csv('neighborhood_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling allowed gyms data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame\n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch gyms in a neighborhood\n",
    "def fetch_gyms(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    gym_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius=neighborhood[\"radius\"],\n",
    "        type='gym',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            gym_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius=neighborhood[\"radius\"],\n",
    "                type='gym',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return gym_list\n",
    "\n",
    "# Fetch gyms for each neighborhood in the DataFrame\n",
    "all_gyms = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_gyms = fetch_gyms(neighborhood_info)\n",
    "    all_gyms.extend(neighborhood_gyms)\n",
    "\n",
    "# Create a DataFrame from the combined list of gyms\n",
    "gym_df = pd.DataFrame(all_gyms)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "gym_df.to_excel('Allowed_gyms.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling allowed restaurant data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame\n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch restaurants in a neighborhood\n",
    "def fetch_business(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    restaurant_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius=neighborhood[\"radius\"],\n",
    "        type='restaurant',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            restaurant_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius=neighborhood[\"radius\"],\n",
    "                type='restaurant',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return restaurant_list\n",
    "\n",
    "# Fetch restaurants for each neighborhood in the DataFrame\n",
    "all_restaurants = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_restaurants = fetch_business(neighborhood_info)\n",
    "    all_restaurants.extend(neighborhood_restaurants)\n",
    "\n",
    "# Create a DataFrame from the combined list of restaurants\n",
    "restaurant_df = pd.DataFrame(all_restaurants)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "restaurant_df.to_excel('Allowed_restaurant.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling allowed banks data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame\n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch banks in a neighborhood\n",
    "def fetch_banks(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    bank_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius=neighborhood[\"radius\"],\n",
    "        type='bank',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            bank_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius=neighborhood[\"radius\"],\n",
    "                type='bank',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return bank_list\n",
    "\n",
    "# Fetch banks for each neighborhood in the DataFrame\n",
    "all_banks = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_banks = fetch_banks(neighborhood_info)\n",
    "    all_banks.extend(neighborhood_banks)\n",
    "\n",
    "# Create a DataFrame from the combined list of banks\n",
    "bank_df = pd.DataFrame(all_banks)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "bank_df.to_excel('Allowed_banks.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am noticing many duplicates in the place_id of the businessess, which is not a big deal in this scenario, but i am considering using a smaller search radius (1,500) around the neighbourhoods to see if the number of duplicates will reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling allowed pharmacies data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame\n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch pharmacy in a neighborhood \n",
    "def fetch_pharmacy(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    pharmacy_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius='1500',\n",
    "        type='pharmacy',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            pharmacy_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius='1500',\n",
    "                type='pharmacy',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return pharmacy_list\n",
    "\n",
    "# Fetch pharmacy for each neighborhood in the DataFrame\n",
    "all_pharmacy = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_pharmacy = fetch_pharmacy(neighborhood_info)\n",
    "    all_pharmacy.extend(neighborhood_pharmacy)\n",
    "\n",
    "# Create a DataFrame from the combined list of pharmacy\n",
    "pharmacy_df = pd.DataFrame(all_pharmacy)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "pharmacy_df.to_excel('Allowed_pharmacy.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
