{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googlemaps in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.10.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests<3.0,>=2.20.0 in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from googlemaps) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.20.0->googlemaps) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.1.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\stean\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import openpyxl\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = open('API.txt','r').read()\n",
    "map_client = googlemaps.Client(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the cordinates of the all neighborhoods in the property dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of neighborhood names in Baltimore\n",
    "neighborhood_names = [\n",
    "    \"Mount Washington\",\n",
    "    \"Fells Point\",\n",
    "    \"Clifton\",\n",
    "    \"Downtown\",\n",
    "    \"Arlington\",\n",
    "    \"Carroll\",\n",
    "    \"Purnell\",\n",
    "    \"Greater Northwood Covenant Association\",\n",
    "    \"Northwood\",\n",
    "    \"Locust Point\",\n",
    "    \"Lakeland\",\n",
    "    \"Bolton Hill\",\n",
    "    \"Highlandtown\",\n",
    "    \"Gwynn Oak\",\n",
    "    \"Druid Hill Park\",\n",
    "    \"Otterbein\",\n",
    "    \"Franklintown\",\n",
    "    \"Waverly\",\n",
    "    \"Charles Village\",\n",
    "    \"Old Goucher\",\n",
    "    \"Cherry Hill\",\n",
    "    \"South Baltimore\",\n",
    "    \"Woodberry\",\n",
    "    \"Govans\",\n",
    "    \"Sharp Leadenhall\",\n",
    "    \"Tuscany - Canterbury\",\n",
    "    \"East Case\",\n",
    "    \"Grove Park\",\n",
    "    \"Mid-Town Belvedere\",\n",
    "    \"New North Roland Park - Poplar Hill\",\n",
    "    \"Mosher\",\n",
    "    \"Middle East\",\n",
    "    \"Riverside\",\n",
    "    \"Garwyn Oaks\",\n",
    "    \"Mount Holly\",\n",
    "    \"Elwood Park\",\n",
    "    \"Federal Hill-Montgomery\",\n",
    "    \"West Forest Park\",\n",
    "    \"Inner Harbor\",\n",
    "    \"Ridgely's Delight\",\n",
    "    \"Ednor Gardens - Lakeside\",\n",
    "    \"Brooklyn\",\n",
    "    \"Raspeburg\",\n",
    "    \"Medfield\",\n",
    "    \"Panway - Braddish\",\n",
    "    \"Forest Park\",\n",
    "    \"Harford - Echodale - Perring Parkway\",\n",
    "    \"Station North\",\n",
    "    \"Upper Fells Point\",\n",
    "    \"Hampden\",\n",
    "    \"Pen Lucy\",\n",
    "    \"Oakenshawe\",\n",
    "    \"Harwood\",\n",
    "    \"Coldstream - Homestead - Montebello\",\n",
    "    \"Bridgeview-Greenlawn\",\n",
    "    \"Gay Street\",\n",
    "    \"Franklin\",\n",
    "    \"Pigtown\",\n",
    "    \"Orangeville\",\n",
    "    \"Better Waverly\",\n",
    "    \"Butchers Hill\",\n",
    "    \"Evergreen Lawn\",\n",
    "    \"Morrell Park\",\n",
    "    \"Glenham-Belford\",\n",
    "    \"Western\",\n",
    "    \"Madison - Eastend\",\n",
    "    \"Walbrook\",\n",
    "    \"Abell\",\n",
    "    \"East Baltimore Midway\",\n",
    "    \"Remington\",\n",
    "    \"Coppin Heights\",\n",
    "    \"Hollins Market\",\n",
    "    \"Lauraville\",\n",
    "    \"Mondawmin\",\n",
    "    \"Canton\",\n",
    "    \"Barre Circle\",\n",
    "    \"Barclay\",\n",
    "    \"Windsor Hills\",\n",
    "    \"Wyndhurst\",\n",
    "    \"Wyman Park\",\n",
    "    \"Rosemont\",\n",
    "    \"NW Community Action\",\n",
    "    \"Winchester\",\n",
    "    \"Woodring\",\n",
    "    \"Curtis Bay\",\n",
    "    \"Milton - Montford\",\n",
    "]\n",
    "\n",
    "# Create an empty list to store neighborhood data\n",
    "neighborhood_data = []\n",
    "\n",
    "# Function to geocode neighborhood names and get coordinates and radii\n",
    "def geocode_neighborhoods(names):\n",
    "    for name in names:\n",
    "        try:\n",
    "            # Geocode the neighborhood name\n",
    "            geocode_result = map_client.geocode(name + ', Baltimore, MD, USA')\n",
    "\n",
    "            # Extracting latitude and longitude from the geocoding result\n",
    "            if geocode_result and 'geometry' in geocode_result[0]:\n",
    "                location = geocode_result[0]['geometry']['location']\n",
    "                latitude = location['lat']\n",
    "                longitude = location['lng']\n",
    "\n",
    "                radius = 2000\n",
    "\n",
    "                # Create a dictionary with neighborhood data\n",
    "                neighborhood_info = {\n",
    "                    \"name\": name,\n",
    "                    \"location\": f\"{latitude},{longitude}\",\n",
    "                    \"radius\": radius\n",
    "                }\n",
    "\n",
    "                neighborhood_data.append(neighborhood_info)\n",
    "            else:\n",
    "                print(f\"Could not geocode {name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error geocoding {name}: {str(e)}\")\n",
    "\n",
    "# Calling the function to geocode neighborhood names\n",
    "geocode_neighborhoods(neighborhood_names)\n",
    "\n",
    "# Creating a DataFrame from the neighborhood data\n",
    "neighborhood_df = pd.DataFrame(neighborhood_data)\n",
    "\n",
    "# Print the DataFrame or save it to a CSV file\n",
    "print(neighborhood_df)\n",
    "neighborhood_df.to_csv('neighborhood_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling allowed gyms data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame\n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch gyms in a neighborhood\n",
    "def fetch_gyms(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    gym_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius=neighborhood[\"radius\"],\n",
    "        type='gym',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            gym_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius=neighborhood[\"radius\"],\n",
    "                type='gym',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return gym_list\n",
    "\n",
    "# Fetch gyms for each neighborhood in the DataFrame\n",
    "all_gyms = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_gyms = fetch_gyms(neighborhood_info)\n",
    "    all_gyms.extend(neighborhood_gyms)\n",
    "\n",
    "# Create a DataFrame from the combined list of gyms\n",
    "gym_df = pd.DataFrame(all_gyms)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "gym_df.to_excel('Allowed_gyms.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling allowed restaurant data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame\n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch restaurants in a neighborhood\n",
    "def fetch_business(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    restaurant_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius=neighborhood[\"radius\"],\n",
    "        type='restaurant',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            restaurant_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius=neighborhood[\"radius\"],\n",
    "                type='restaurant',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return restaurant_list\n",
    "\n",
    "# Fetch restaurants for each neighborhood in the DataFrame\n",
    "all_restaurants = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_restaurants = fetch_business(neighborhood_info)\n",
    "    all_restaurants.extend(neighborhood_restaurants)\n",
    "\n",
    "# Create a DataFrame from the combined list of restaurants\n",
    "restaurant_df = pd.DataFrame(all_restaurants)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "restaurant_df.to_excel('Allowed_restaurant.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling allowed banks data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame\n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch banks in a neighborhood\n",
    "def fetch_banks(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    bank_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius=neighborhood[\"radius\"],\n",
    "        type='bank',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            bank_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius=neighborhood[\"radius\"],\n",
    "                type='bank',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return bank_list\n",
    "\n",
    "# Fetch banks for each neighborhood in the DataFrame\n",
    "all_banks = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_banks = fetch_banks(neighborhood_info)\n",
    "    all_banks.extend(neighborhood_banks)\n",
    "\n",
    "# Create a DataFrame from the combined list of banks\n",
    "bank_df = pd.DataFrame(all_banks)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "bank_df.to_excel('Allowed_banks.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am noticing many duplicates in the place_id of the businessess, which is not a big deal in this scenario, but i am considering using a smaller search radius (1,500) around the neighbourhoods to see if the number of duplicates will reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling allowed pharmacies data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame\n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch pharmacy in a neighborhood \n",
    "def fetch_pharmacy(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    pharmacy_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius='1500',\n",
    "        type='pharmacy',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            pharmacy_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius='1500',\n",
    "                type='pharmacy',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return pharmacy_list\n",
    "\n",
    "# Fetch pharmacy for each neighborhood in the DataFrame\n",
    "all_pharmacy = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_pharmacy = fetch_pharmacy(neighborhood_info)\n",
    "    all_pharmacy.extend(neighborhood_pharmacy)\n",
    "\n",
    "# Create a DataFrame from the combined list of pharmacy\n",
    "pharmacy_df = pd.DataFrame(all_pharmacy)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "pharmacy_df.to_excel('Allowed_pharmacy.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling allowed supermarkets data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame\n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch supermarkets in a neighborhood \n",
    "def fetch_supermarket(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    supermarket_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius='1500',\n",
    "        type='supermarket',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            supermarket_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius='1500',\n",
    "                type='supermarket',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return supermarket_list\n",
    "\n",
    "# Fetch supermarkets for each neighborhood in the DataFrame\n",
    "all_supermarket = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_supermarket = fetch_supermarket(neighborhood_info)\n",
    "    all_supermarket.extend(neighborhood_supermarket)\n",
    "\n",
    "# Create a DataFrame from the combined list of supermarkets\n",
    "supermarket_df = pd.DataFrame(all_supermarket)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "supermarket_df.to_excel('Allowed_supermarkets.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling allowed park data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame \n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch parks in a neighborhood \n",
    "def fetch_park(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    park_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius='1500',\n",
    "        type='park',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            park_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius='1500',\n",
    "                type='park',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return park_list\n",
    "\n",
    "# Fetch parks for each neighborhood in the DataFrame\n",
    "all_park = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_park = fetch_park(neighborhood_info)\n",
    "    all_park.extend(neighborhood_park)\n",
    "\n",
    "# Create a DataFrame from the combined list of parks\n",
    "park_df = pd.DataFrame(all_park)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "park_df.to_excel('Allowed_parks.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Pulling allowed night_club data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame \n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch night_clubs in a neighborhood \n",
    "def fetch_night_club(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    night_club_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius='1500',\n",
    "        type='night_club',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            night_club_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius='1500',\n",
    "                type='night_club',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return night_club_list\n",
    "\n",
    "# Fetch night_clubs for each neighborhood in the DataFrame\n",
    "all_night_club = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_night_club = fetch_night_club(neighborhood_info)\n",
    "    all_night_club.extend(neighborhood_night_club)\n",
    "\n",
    "# Create a DataFrame from the combined list of night_clubs\n",
    "night_club_df = pd.DataFrame(all_night_club)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "night_club_df.to_excel('Allowed_night_clubs.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Pulling allowed hospital data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame \n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch hospitals in a neighborhood \n",
    "def fetch_hospital(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    hospital_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius='1500',\n",
    "        type='hospital',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            hospital_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius='1500',\n",
    "                type='hospital',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return hospital_list\n",
    "\n",
    "# Fetch hospitals for each neighborhood in the DataFrame\n",
    "all_hospital = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_hospital = fetch_hospital(neighborhood_info)\n",
    "    all_hospital.extend(neighborhood_hospital)\n",
    "\n",
    "# Create a DataFrame from the combined list of hospitals\n",
    "hospital_df = pd.DataFrame(all_hospital)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "hospital_df.to_excel('Allowed_hospitals.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Pulling allowed bars data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame \n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch bars in a neighborhood \n",
    "def fetch_bar(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    bar_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius='1500',\n",
    "        type='bar',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            bar_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius='1500',\n",
    "                type='bar',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return bar_list\n",
    "\n",
    "# Fetch bar for each neighborhood in the DataFrame\n",
    "all_bar = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_bar = fetch_bar(neighborhood_info)\n",
    "    all_bar.extend(neighborhood_bar)\n",
    "\n",
    "# Create a DataFrame from the combined list of bars\n",
    "bar_df = pd.DataFrame(all_bar)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "bar_df.to_excel('Allowed_bars.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Pulling allowed beauty_salon data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame \n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# Function to fetch beauty_salons in a neighborhood \n",
    "def fetch_beauty_salon(neighborhood):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    beauty_salon_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius='1500',\n",
    "        type='beauty_salon',  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            beauty_salon_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius='1500',\n",
    "                type='beauty_salon',\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return beauty_salon_list\n",
    "\n",
    "# Fetch beauty_salon for each neighborhood in the DataFrame\n",
    "all_beauty_salon = []\n",
    "\n",
    "for index, row in neighborhood_df.iterrows():\n",
    "    neighborhood_info = {\n",
    "        \"name\": row[\"name\"],\n",
    "        \"location\": row[\"location\"],\n",
    "        \"radius\": row[\"radius\"]\n",
    "    }\n",
    "    neighborhood_beauty_salon = fetch_beauty_salon(neighborhood_info)\n",
    "    all_beauty_salon.extend(neighborhood_beauty_salon)\n",
    "\n",
    "# Create a DataFrame from the combined list of beauty_salons\n",
    "beauty_salon_df = pd.DataFrame(all_beauty_salon)\n",
    "\n",
    "# Save the merged dataset to an Excel file\n",
    "beauty_salon_df.to_excel('Allowed_beauty_salons.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing code to create a function for this code for next business types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the neighborhood details from a CSV file into a DataFrame \n",
    "neighborhood_df = pd.read_csv('neighborhood_data.csv')\n",
    "\n",
    "# General function to fetch businesses in a neighborhood \n",
    "def fetch_business(neighborhood, business_type):\n",
    "    allowed_columns = [\"place_id\", \"geometry\"]  # Specifying the allowed columns\n",
    "\n",
    "    business_list = []\n",
    "    response = map_client.places_nearby(\n",
    "        location=neighborhood[\"location\"],\n",
    "        radius='1500',\n",
    "        type=business_type,  \n",
    "    )\n",
    "\n",
    "    while 'results' in response:\n",
    "        for result in response['results']:\n",
    "            # Filter columns to keep only allowed ones\n",
    "            filtered_result = {key: result[key] for key in allowed_columns}\n",
    "\n",
    "            # Add neighborhood information\n",
    "            filtered_result['neighborhood'] = neighborhood[\"location\"]\n",
    "\n",
    "            business_list.append(filtered_result)\n",
    "\n",
    "        time.sleep(2)  # Pause to avoid rate limiting issues\n",
    "        if 'next_page_token' in response:\n",
    "            response = map_client.places_nearby(\n",
    "                location=neighborhood[\"location\"],\n",
    "                radius='1500',\n",
    "                type=business_type,\n",
    "                page_token=response['next_page_token']\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return business_list\n",
    "\n",
    "def fetch_and_save_business_data(business_type, excel_filename):\n",
    "    # Fetch businesses for each neighborhood in the DataFrame\n",
    "    all_businesses = []\n",
    "\n",
    "    for index, row in neighborhood_df.iterrows():\n",
    "        neighborhood_info = {\n",
    "            \"name\": row[\"name\"],\n",
    "            \"location\": row[\"location\"],\n",
    "            \"radius\": row[\"radius\"]\n",
    "        }\n",
    "        neighborhood_business = fetch_business(neighborhood_info, business_type)\n",
    "        all_businesses.extend(neighborhood_business)\n",
    "\n",
    "    # Create a DataFrame from the combined list of businesses\n",
    "    business_df = pd.DataFrame(all_businesses)\n",
    "\n",
    "    # Save the merged dataset to an Excel file\n",
    "    business_df.to_excel(excel_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing function on pulling allowed art_gallery data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get art_gallery data\n",
    "fetch_and_save_business_data('art_gallery', 'Allowed_art_gallerys.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using fetch and save function to pull allowed police location data for Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_and_save_business_data('police', 'police.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formating geometry collumn to show just the location coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing a function to extract and format the coordinates from the geometry column\n",
    "\n",
    "def extract_lat_lng(geometry):\n",
    "    \"\"\"\n",
    "    Extracts latitude and longitude values from the geometry column.\n",
    "    \"\"\"\n",
    "    # Convert string representation of dictionary to a dictionary\n",
    "    geometry_dict = ast.literal_eval(geometry)\n",
    "    \n",
    "    # Extract latitude and longitude values\n",
    "    lat = geometry_dict['location']['lat']\n",
    "    lng = geometry_dict['location']['lng']\n",
    "    \n",
    "    # Return as a string\n",
    "    return f\"{lat},{lng}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out location data for Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the XLSX file into a DataFrame\n",
    "rest = pd.read_excel('Allowed_restaurant.xlsx')\n",
    "\n",
    "# Apply the extraction function to the 'geometry' column\n",
    "rest['geometry'] = rest['geometry'].apply(extract_lat_lng)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "rest.to_csv('Allowed_restaurantr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out location data for Art Gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the XLSX file into a DataFrame\n",
    "art = pd.read_excel('Allowed_art_gallerys.xlsx')\n",
    "\n",
    "# Applying the extraction function to the 'geometry' column\n",
    "art['geometry'] = art['geometry'].apply(extract_lat_lng)\n",
    "\n",
    "# Saving the DataFrame as a CSV file\n",
    "art.to_csv('Filtered_art_gallerys.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out location data for Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the XLSX file into a DataFrame\n",
    "bank = pd.read_excel('Allowed_banks.xlsx')\n",
    "\n",
    "# Applying the extraction function to the 'geometry' column\n",
    "bank['geometry'] = bank['geometry'].apply(extract_lat_lng)\n",
    "\n",
    "# Saving the DataFrame as a CSV file\n",
    "bank.to_csv('Filtered_banks.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
